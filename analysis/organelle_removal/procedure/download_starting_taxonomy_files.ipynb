{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Starting Taxonomy Files\n",
    "\n",
    "In order to remove coral mitochondria, we need to first build supplemented versions of the greengenes and SILVA reference databases. In this notebook we automated downloading and extracting the databases.\n",
    "\n",
    "NOTE: these references are large, so it will take a while for them to download, and you should expect them to occupy several Gb of hard drive space. (I'd hesitate before running if < 15Gb are free on your harddrive).\n",
    "\n",
    "gg_13_8_otus.tar.gz (from ftp://greengenes.microbio.me/greengenes_release/gg_13_5/gg_13_8_otus.tar.gz)  \n",
    "Silva_132_release.zip (from https://www.arb-silva.de/fileadmin/silva_databases/qiime/Silva_132_release.zip)    \n",
    "MeTaxa2(from https://microbiology.se/sw/Metaxa2_2.2.1.tar.gz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions \n",
    "\n",
    "We will define a couple of utility functions for downloading files from a given web address and for creating a direcotry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up utility functions for downloading data and organizing our folders\n",
    "\n",
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "def download_file(url, local_filepath):\n",
    "    \"\"\"Download a file from a remote url and save to a local filepath\n",
    "    \n",
    "    url - the web address of the file you want to download as a string\n",
    "    local_filepath - the local filepath to which the file will be saved\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Downloading file: {url}\")\n",
    "    # This is slightly convoluted-looking, but we are getting a response from the webpage and\n",
    "    # then copying that to the file. \n",
    "\n",
    "    #Hat-tip to stack overflow: \n",
    "    #https://stackoverflow.com/questions/7243750/download-file-from-web-in-python-3\n",
    "\n",
    "    with urllib.request.urlopen(url) as response, open(local_filepath, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "    \n",
    "    print(f\"Saved to local filepath: {local_filepath}\")\n",
    "    \n",
    "def make_directory(path):\n",
    "    \"\"\"Make a directory, but proceed without errors if it fails\n",
    "    path -- the path to the directory (e.g. \"../output/taxonomy_references\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (f\"Creation of directory {path} failed\")\n",
    "    else:\n",
    "        print (f\"Created the directory {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up filepaths\n",
    "\n",
    "This notebook assumes that you ran jupyter notebook in the organelle_removal folder, then opened and ran the .ipynb file in the procedure folder. As such it assumes that the output folder will be in ../output/  relative to the starting working directory. If this is not correct (e.g. because your folders are organized differently), you can replace the data_folder variable with a new absolute path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths and urls\n",
    "data_folder = os.path.abspath(\"../output/taxonomy_references/\")\n",
    "#data_folder = \"../output/taxonomy_references/\"\n",
    "\n",
    "gg_url = \"ftp://greengenes.microbio.me/greengenes_release/gg_13_5/gg_13_8_otus.tar.gz\"\n",
    "local_gg_filename = \"gg_13_8_otus.tar.gz\"\n",
    "\n",
    "silva_url = \" https://www.arb-silva.de/fileadmin/silva_databases/qiime/Silva_132_release.zip\"\n",
    "local_silva_filename = \"Silva_132_release.zip\"\n",
    "local_silva_filepath = os.path.join(data_folder,local_silva_filename)\n",
    "local_gg_filepath = os.path.join(data_folder,local_gg_filename)\n",
    "\n",
    "metaxa2_url = \"https://microbiology.se/sw/Metaxa2_2.2.1.tar.gz\"\n",
    "local_metaxa2_filename = \"Metaxa2_2.2.1.tar.gz\"\n",
    "local_metaxa2_filepath = os.path.join(data_folder,local_metaxa2_filename)\n",
    "metaxa2_fasta_filepath = os.path.join(data_folder,'metaxa2.fasta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in existing output folder /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references\n"
     ]
    }
   ],
   "source": [
    "#### Set up a folder to hold large taxonomy files\n",
    "import os\n",
    "\n",
    "# create the data folder if it doesn't already exist\n",
    "if not os.path.exists(data_folder):\n",
    "    print(f\"Creating new output folder {data_folder}\")\n",
    "    make_directory(data_folder)\n",
    "    \n",
    "else:\n",
    "    print(f\"Results will be saved in existing output folder {data_folder}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the Greengenes Taxonomy\n",
    "\n",
    "We'll now download the greengenes 13_8 taxonomy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file: ftp://greengenes.microbio.me/greengenes_release/gg_13_5/gg_13_8_otus.tar.gz\n",
      "Saved to local filepath: /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references/gg_13_8_otus.tar.gz\n"
     ]
    }
   ],
   "source": [
    "download_file(url=gg_url,local_filepath = local_gg_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to expand the greengenes .tar.gz file into our input folder so we can access the contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar = tarfile.open(local_gg_filepath, \"r:gz\")\n",
    "tar.extractall(path=data_folder)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Expand the SILVA 132 release\n",
    "\n",
    "Now we'll download the SIVLA 132 release and decompress it.\n",
    "NOTE: this is a large (~2.47 Gb) file, so it may take a while to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file:  https://www.arb-silva.de/fileadmin/silva_databases/qiime/Silva_132_release.zip\n",
      "Saved to local filepath: /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references/Silva_132_release.zip\n"
     ]
    }
   ],
   "source": [
    "download_file(url=silva_url,local_filepath = local_silva_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SILVA database...\n",
      "Extracted the SILVA 132 database into: /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references\n"
     ]
    }
   ],
   "source": [
    "from zipfile import is_zipfile, ZipFile\n",
    "\n",
    "if not is_zipfile(local_silva_filepath):\n",
    "    raise ValueError(\"The SILVA database zip file {local_silva_filepath} doesn't look like a zip file. Was it downloaded correctly?\")\n",
    "\n",
    "silva_zipfile = ZipFile(local_silva_filepath)\n",
    "\n",
    "#Obnoxiously this file contains a _MACOSX subfolder. We don't want to unzip that...\n",
    "files_to_extract = [m for m in silva_zipfile.namelist() if \"_MACOSX\" not in m]\n",
    "print(\"Extracting SILVA database...\")\n",
    "silva_zipfile.extractall(path = data_folder,members = files_to_extract)\n",
    "silva_zipfile.close()\n",
    "print(f\"Extracted the SILVA 132 database into: {data_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Expand MeTaxa2\n",
    "\n",
    "We want to get sequences from a BLAST repository generated for the MeTaxa2 project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file: https://microbiology.se/sw/Metaxa2_2.2.1.tar.gz\n",
      "Saved to local filepath: /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references/Metaxa2_2.2.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "download_file(url=metaxa2_url,local_filepath=local_metaxa2_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now extract the MeTaxa2 software into our data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to extract .tar.gz file: /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references/Metaxa2_2.2.1.tar.gz\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "print(f\"About to extract .tar.gz file: {local_metaxa2_filepath}\")\n",
    "tar = tarfile.open(local_metaxa2_filepath, \"r:gz\")\n",
    "tar.extractall(path=data_folder)\n",
    "tar.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a FASTA file out of the Metaxa2 BLAST database\n",
    "\n",
    "The MeTaxa2 software supplies a BLAST database, but not a FASTA file for the underlying sequences. In this step we convert these files to the FASTA format using the blastdbcmd program from BLAST+. \n",
    "\n",
    "This step requires BLAST+ installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started in working directory: /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/procedure\n",
      "Changed folder to  /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references/Metaxa2_2.2.1/metaxa2_db/SSU\n",
      "Generating a FASTA file from the MeTaxa2 BLAST database\n",
      "Resulting FASTA file(s):\n",
      "./metaxa2.fasta\n",
      "Moved metaxa2.fasta to /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/output/taxonomy_references/metaxa2.fasta\n",
      "Changed working directory back to:  /Users/jzaneveld/Dropbox/Zaneveld_Lab_Organization/Projects/GCMP_Global_Disease/gcmp_global_disease/analysis/organelle_removal/procedure\n"
     ]
    }
   ],
   "source": [
    "starting_folder = os.getcwd()\n",
    "print(f\"Started in working directory: {starting_folder}\")\n",
    "metaxa2_db_folder = os.path.join(data_folder,\"Metaxa2_2.2.1\",\"metaxa2_db\",\"SSU\")\n",
    "os.chdir(metaxa2_db_folder)\n",
    "print(\"Changed folder to \", os.getcwd())\n",
    "\n",
    "print(\"Generating a FASTA file from the MeTaxa2 BLAST database\")\n",
    "#Step out of python for a moment to extract a FASTA file from the Metaxa2 BLAST db\n",
    "!blastdbcmd -entry all -db blast -out metaxa2.fasta\n",
    "\n",
    "print(\"Resulting FASTA file(s):\")\n",
    "!ls ./*.fasta\n",
    "!mv metaxa2.fasta $metaxa2_fasta_filepath\n",
    "\n",
    "print(f\"Moved metaxa2.fasta to {metaxa2_fasta_filepath}\")\n",
    "\n",
    "os.chdir(starting_folder)\n",
    "print(\"Changed working directory back to: \", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxonomy reference files downloaded\n",
    "\n",
    "The taxonomy reference files should now all be downloaded into the data directory. The next step is to supplement the Greengenes and SILVA taxonomies with the MeTaxa2 mitochondrial data to better annotate coral sequences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
